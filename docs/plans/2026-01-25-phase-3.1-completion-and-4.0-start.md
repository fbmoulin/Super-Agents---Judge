# Phase 3.1 Completion + Phase 4.0 Start

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Complete metrics dashboard integration and begin Redis caching implementation.

**Architecture:** Phase 3.1 connects n8n workflow to Supabase for real-time metrics. Phase 4.0 adds Redis cache layer before RAG operations to reduce latency by 30%+.

**Tech Stack:** n8n Cloud, Supabase (PostgreSQL + Realtime), Next.js Dashboard, Redis Cloud (Upstash)

---

## Part A: Complete Phase 3.1 (2 Tasks)

### Task 1: Configure n8n Cloud Environment Variables

**Type:** Manual Configuration (n8n Cloud UI)

**Prerequisite:** Access to https://lexintel.app.n8n.cloud

**Step 1: Access n8n Cloud Settings**

Navigate to: `Settings → Variables`

**Step 2: Add Supabase URL**

```
Name: SUPABASE_URL
Value: https://uxhfwlerodittdmrcgnp.supabase.co
```

**Step 3: Add Supabase Anon Key**

```
Name: SUPABASE_ANON_KEY
Value: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InV4aGZ3bGVyb2RpdHRkbXJjZ25wIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Njc5MjEwNDYsImV4cCI6MjA4MzQ5NzA0Nn0.C8_ouc3D2eRgpjkbfifnfpSwIK8ZIiYL-tbDDLZgUek
```

**Step 4: Verify variables saved**

Expected: Both variables appear in the Variables list

---

### Task 2: End-to-End Integration Test

**Blocked by:** Task 1

**Files:**
- Test: `n8n_workflow_v3.1_metrics.json` (import to n8n Cloud)
- Verify: Supabase tables `executions`, `quality_scores`

**Step 1: Import workflow to n8n Cloud**

1. Open n8n Cloud
2. Import `n8n_workflow_v3.1_metrics.json`
3. Activate workflow

**Step 2: Send test request**

```bash
curl -X POST https://lexintel.app.n8n.cloud/webhook/lex-intelligentia-agentes \
  -H "Content-Type: application/json" \
  -d '{
    "fatos": "O autor celebrou contrato de financiamento de veículo com o réu banco em 15/01/2025. Alega cobrança de juros superiores ao pactuado, com taxa efetiva de 3.5% ao mês quando o contrato previa 2.1%.",
    "questoes": "Houve cobrança de juros abusivos? O autor tem direito à repetição do indébito?",
    "pedidos": "Revisão contratual com redução dos juros. Repetição simples dos valores pagos a maior.",
    "classe_processual": "Procedimento Comum Cível",
    "assunto": "Contratos Bancários - Revisão de Cláusulas"
  }'
```

Expected: HTTP 200 with `success: true`

**Step 3: Verify data in Supabase**

Run this SQL in Supabase SQL Editor:

```sql
SELECT
  e.id,
  e.agent_name,
  e.domain,
  e.duration_ms,
  e.status,
  q.structure_score,
  q.citation_score,
  q.reasoning_score,
  q.overall_score
FROM executions e
LEFT JOIN quality_scores q ON e.id = q.execution_id
ORDER BY e.created_at DESC
LIMIT 5;
```

Expected: At least 1 row with `agent_name = 'agent_BANCARIO'`, `status = 'success'`

**Step 4: Verify Dashboard displays data**

1. Navigate to `http://localhost:3001/dashboard`
2. Confirm new execution appears in "Recent Executions"
3. Confirm metrics update (case count, latency, quality scores)

**Step 5: Document completion**

```bash
# Update validation status
echo "Phase 3.1: COMPLETE - $(date)" >> docs/VALIDATION_COMPLETE.md
git add docs/VALIDATION_COMPLETE.md
git commit -m "docs: mark Phase 3.1 as complete after e2e validation"
```

---

## Part B: Start Phase 4.0 - Redis Caching (5 Tasks)

### Task 3: Setup Redis Cloud (Upstash)

**Type:** Manual Configuration

**Step 1: Create Upstash Redis instance**

1. Go to https://console.upstash.com
2. Create new Redis database
3. Select region closest to n8n Cloud (likely us-east-1)
4. Copy connection details

**Step 2: Note credentials**

```
REDIS_URL: redis://default:***@xxx.upstash.io:6379
REDIS_REST_URL: https://xxx.upstash.io
REDIS_REST_TOKEN: AXxx...
```

**Step 3: Add to n8n Cloud Variables**

```
Name: REDIS_REST_URL
Value: https://xxx.upstash.io

Name: REDIS_REST_TOKEN
Value: AXxx...
```

---

### Task 4: Create Cache Check Node

**Files:**
- Modify: `n8n_workflow_v3.1_metrics.json` → `n8n_workflow_v4.0_cached.json`

**Step 1: Write cache key generator (Code node)**

```javascript
// Cache Key Generator - runs before RAG
const query = $input.first().json.questoes || '';
const domain = $input.first().json.domain || 'unknown';

// Normalize for consistent cache hits
const normalized = query.toLowerCase().trim()
  .replace(/\s+/g, ' ')
  .normalize('NFD').replace(/[\u0300-\u036f]/g, '');

// Generate short hash
const hash = normalized.split('').reduce((a, c) => {
  return ((a << 5) - a + c.charCodeAt(0)) | 0;
}, 0).toString(16).replace('-', 'n');

const cacheKey = `rag:${domain}:${hash}`;

return [{
  json: {
    ...$input.first().json,
    cache_key: cacheKey,
    cache_check_at: new Date().toISOString()
  }
}];
```

**Step 2: Add HTTP Request node for cache GET**

```
Name: Check Cache
Method: GET
URL: {{ $env.REDIS_REST_URL }}/get/{{ $json.cache_key }}
Headers:
  Authorization: Bearer {{ $env.REDIS_REST_TOKEN }}
```

**Step 3: Add IF node for cache hit**

```
Condition: {{ $json.result !== null }}
True: Use Cached (skip RAG)
False: Execute RAG
```

---

### Task 5: Create Cache Store Node

**Step 1: Add HTTP Request node for cache SET**

Place after RAG execution, before Quality Validator.

```
Name: Store Cache
Method: POST
URL: {{ $env.REDIS_REST_URL }}/set/{{ $json.cache_key }}
Headers:
  Authorization: Bearer {{ $env.REDIS_REST_TOKEN }}
  Content-Type: application/json
Body:
{
  "value": {{ JSON.stringify($json.rag_results) }},
  "ex": 3600
}
```

TTL: 3600 seconds (1 hour) for RAG results

**Step 2: Verify cache flow**

Run same test request twice:
- First request: cache miss, full RAG execution
- Second request: cache hit, faster response

---

### Task 6: Add cache_hit to Metrics

**Files:**
- Modify: Metrics Logger node in workflow

**Step 1: Update Metrics Logger payload**

Add `cache_hit` field:

```javascript
{
  "p_workflow_id": "{{ $workflow.id }}",
  "p_agent_name": "{{ $json.agent_name }}",
  "p_domain": "{{ $json.domain }}",
  "p_cache_hit": {{ $json.cache_hit || false }},
  // ... rest of fields
}
```

**Step 2: Verify in Supabase**

```sql
SELECT
  COUNT(*) as total,
  COUNT(*) FILTER (WHERE cache_hit = true) as hits,
  ROUND(100.0 * COUNT(*) FILTER (WHERE cache_hit = true) / COUNT(*), 1) as hit_rate
FROM executions
WHERE created_at > NOW() - INTERVAL '1 day';
```

---

### Task 7: Export and Commit Workflow v4.0

**Step 1: Export workflow from n8n**

Save as `n8n_workflow_v4.0_cached.json`

**Step 2: Commit**

```bash
git add n8n_workflow_v4.0_cached.json
git commit -m "feat(n8n): add Redis caching layer for RAG results (Phase 4.0)"
```

**Step 3: Update documentation**

```bash
# Update CLAUDE.md version table
# Update SESSION_HANDOFF doc
git add CLAUDE.md docs/
git commit -m "docs: update for Phase 4.0 caching implementation"
```

---

## Success Criteria

### Phase 3.1 Complete When:
- [ ] n8n Cloud has SUPABASE_URL and SUPABASE_ANON_KEY configured
- [ ] Test request returns success with metrics logged
- [ ] Dashboard shows real-time updates
- [ ] JOIN query returns data in both tables

### Phase 4.0 Complete When:
- [ ] Redis Cloud configured with credentials in n8n
- [ ] Cache check node runs before RAG
- [ ] Cache store node saves results with 1hr TTL
- [ ] Metrics show cache_hit tracking
- [ ] Second identical request shows cache hit

---

## Estimated Effort

| Task | Type | Time |
|------|------|------|
| Task 1 | Manual | 5 min |
| Task 2 | Test | 10 min |
| Task 3 | Manual | 10 min |
| Task 4 | Code | 15 min |
| Task 5 | Code | 10 min |
| Task 6 | Code | 5 min |
| Task 7 | Git | 5 min |

**Total:** ~1 hour

---

*Plan created: 2026-01-25 20:25 PST*
